import asyncio
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from googletrans import Translator
import os
from webdriver_manager.chrome import ChromeDriverManager
import urllib.parse

MAX_URL_LENGTH = 2000  # Giá»›i háº¡n Ä‘á»™ dÃ i URL
import os
import time
import requests
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import undetected_chromedriver as uc
from urllib.parse import urlparse

SIM_THRESHOLD = 0.60

# Danh sÃ¡ch cÃ¡c domain cáº§n loáº¡i trá»«
EXCLUDED_DOMAINS = [
    "google.com",
    "accounts.google.com",
    "policies.google.com",
    "support.google.com",
    "myactivity.google.com",
    "www.google.com.vn",
    "www.google.com",
]

def is_valid_article_url(url):
    try:
        domain = urlparse(url).netloc
        for excluded in EXCLUDED_DOMAINS:
            if excluded in domain:
                return False
        return True
    except:
        return False

def extract_info_from_article(page_url):
    try:
        response = requests.get(page_url, timeout=5)
        if response.status_code != 200:
            return {"description": "KhÃ´ng rÃµ", "source_page": page_url}

        soup = BeautifulSoup(response.text, "html.parser")
        paragraphs = soup.find_all("p")
        description = " ".join([p.text.strip() for p in paragraphs]) if paragraphs else "KhÃ´ng rÃµ"

        return {
            "description": description,
            "source_page": page_url
        }
    except Exception as e:
        return {
            "description": f"Lá»—i phÃ¢n tÃ­ch bÃ i bÃ¡o: {e}",
            "source_page": page_url
        }

def search_google_and_extract_info(query):
    print(f"ğŸ” Äang tÃ¬m kiáº¿m bÃ i bÃ¡o tá»« Google vá»›i tá»« khÃ³a: {query}...")

    chrome_options = uc.ChromeOptions()
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-popup-blocking")
    chrome_options.add_argument("--disable-notifications")
    chrome_options.add_argument("--disable-infobars")
    # chrome_options.add_argument("--headless=new")  # Bá» comment náº¿u muá»‘n cháº¡y áº©n

    driver = uc.Chrome(options=chrome_options)

    try:
        driver.get("https://www.google.com/")
        driver.maximize_window()
        time.sleep(2)

        # TÃ¬m kiáº¿m trÃªn Google vá»›i tá»« khÃ³a nháº­p vÃ o
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.NAME, "q"))
        )
        search_box.send_keys(query)
        search_box.submit()  # Báº¥m Enter Ä‘á»ƒ tÃ¬m kiáº¿m
        time.sleep(3)  # TÄƒng thá»i gian chá» Ä‘á»ƒ trang táº£i xong

        # Láº¥y danh sÃ¡ch cÃ¡c liÃªn káº¿t bÃ i bÃ¡o liÃªn quan
        article_links = driver.find_elements(By.XPATH, '//a[contains(@href, "http")]')

        seen_domains = set()
        matched_articles = []

        for link in article_links:
            url = link.get_attribute("href")
            if not url:
                continue

            domain = urlparse(url).netloc
            if domain in seen_domains:
                continue

            if not is_valid_article_url(url):
                continue

            seen_domains.add(domain)

            article_info = extract_info_from_article(url)
            article_info["source_page"] = url
            matched_articles.append(article_info)

            if len(matched_articles) >= 10:
                break

        driver.quit()

        return {
            "source": "Google Search (Selenium)",
            "matched_articles": matched_articles
        }

    except Exception as ex:
        driver.quit()
        return {"error": f"Lá»—i khi tÃ¬m kiáº¿m: {ex}"}

# VÃ­ dá»¥ cháº¡y:
if __name__ == "__main__":
    query = input("Nháº­p tá»« khÃ³a tÃ¬m kiáº¿m: ")  # Nháº­p tá»« khÃ³a tÃ¬m kiáº¿m
    result = search_google_and_extract_info(query)
    print(result)

def truncate_text(text, max_length=MAX_URL_LENGTH):
    if len(text) > max_length:
        return text[:max_length]
    return text

async def translate_text(text, src='en', dest='vi'):
    text = truncate_text(text)
    translator = Translator()
    # Sá»­ dá»¥ng async/await Ä‘á»ƒ Ä‘á»£i dá»‹ch
    translated = await translator.translate(text, src=src, dest=dest)
    return translated.text

async def search_and_scrape(keywords):
    # Táº¡o URL Wikipedia tiáº¿ng Anh vá»›i tá»« khÃ³a ngÆ°á»i dÃ¹ng nháº­p
    base_url = "https://en.wikipedia.org/wiki/"
    wikipedia_url = base_url + urllib.parse.quote(keywords)

    # Cáº¥u hÃ¬nh trÃ¬nh duyá»‡t Selenium (khÃ´ng hiá»ƒn thá»‹ cá»­a sá»• trÃ¬nh duyá»‡t)
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Cháº¡y á»Ÿ cháº¿ Ä‘á»™ áº©n danh (khÃ´ng má»Ÿ cá»­a sá»• trÃ¬nh duyá»‡t)

    # Khá»Ÿi táº¡o WebDriver
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)

    # Má»Ÿ trang Wikipedia
    driver.get(wikipedia_url)

    try:
        # Chá» tháº» chá»©a ná»™i dung chÃ­nh xuáº¥t hiá»‡n (chá» cho Ä‘áº¿n khi tháº» 'mw-parser-output' cÃ³ máº·t)
        element_present = EC.presence_of_element_located((By.CLASS_NAME, 'mw-parser-output'))
        WebDriverWait(driver, 10).until(element_present)

        # TÃ¬m ná»™i dung trong tháº» 'mw-parser-output'
        main_content = driver.find_element(By.CLASS_NAME, 'mw-parser-output')

        # TrÃ­ch xuáº¥t vÄƒn báº£n tá»« ná»™i dung chÃ­nh
        body_text = main_content.text
        body_text = truncate_text(body_text)

        # Dá»‹ch vÄƒn báº£n sang tiáº¿ng Viá»‡t
        translated_text = await translate_text(body_text, src='en', dest='vi')

        # Táº¡o thÆ° má»¥c vÃ  lÆ°u vÄƒn báº£n vÃ o tá»‡p
        output_dir = 'demo/data_in'
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        base_filename = f"{keywords.replace(' ', '_')}"  # ThÃªm tá»« khÃ³a vÃ o tÃªn tá»‡p
        output_file_path = os.path.join(output_dir, f"{base_filename}.txt")

        # LÆ°u vÄƒn báº£n Ä‘Ã£ dá»‹ch vÃ o tá»‡p
        with open(output_file_path, 'w', encoding='utf-8') as file:
            file.write(translated_text)

        print(f"VÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch vÃ  lÆ°u vÃ o tá»‡p: {output_file_path}")

    except Exception as e:
        print(f"ÄÃ£ xáº£y ra lá»—i: {e}")

    finally:
        # ÄÃ³ng trÃ¬nh duyá»‡t
        driver.quit()

